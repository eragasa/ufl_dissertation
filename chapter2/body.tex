\chapter{MOLECULAR DYNAMICS}
\label{ch:md}
\hfuzz=20pt
\vfuzz=20pt
\hbadness=20000
\vbadness=\maxdimen

Molecular dynanmics (MD) is a simulation approach where the time evolution of a set of interacting atoms is followed by numerically solving their equations of motion.  In MD, the behavior of atoms follow Newtonian mechanics:
\begin{equation}
	  \label{eq:newton_eom}
    \bm{M}\frac{\mathrm{d}^2\bm{R}(t)}
		           {\mathrm{d} t^2}
		=
		\bm{F}(\bm{R}(t))
\end{equation}
where $t$ is time,
$\bm{R} = (\bm{r}_1,...,\bm{r}_{N_\alpha})$ represents the position $\bm{r}_\alpha \in \mathbb{R}^3$ of each atom $\alpha$ for $N_\alpha$ atoms,
$\bm{F} = (\bm{f}_1,...,\bm{f}_{N_\alpha})$ are forces $\bm{f}_\alpha$ acting on each atom,
and $\bm{M}$ is the diagonal mass matrix with the mass of each atom $\alpha$.
The total energy is conserved, even though the kinetic energy and potential energy can change dynamically.

The potential $V$ maps interatomic configurations $\bm{R}$ to provide the potential energy of a system $E_P$.  To evolve a system of atoms, the force $\bm{F}$ is given by the gradient of the potential for each atom $\alpha$,
\begin{equation}
	\label{eq:calc_forces_from_potential}
	 \bm{f}_\alpha
	 =
	 -\nabla_{\bm{r}_\alpha} V(\bm{R}_\alpha),
\end{equation}
 which can then be substituted into Equation \ref{eq:newton_eom}.

\section{Numerical Integration}
A dynamical simulation computes the trajectory $\bm{r}_\alpha(t)$ of each atom $\alpha$ as a function of time, given the initial position $\bm{r}_\alpha(t=0)$ and velocity $\bm{v}_\alpha(t=0)$.  Since Newton's equation of motion is a 2nd order differential equation, an initial condition needs to specify both positions and velocities of all atoms at the initial time.

To evolve the equation of motion numerically, time is typically descretized uniformly by incrementing $t$ by the time step $\Delta t$.  A naive implementation of an integration scheme would use the forward Euler algorithm, which is a truncated Taylor series expansion,
\begin{equation}
	\bm{r}(t+\Delta t)
	=
	\bm{r}(t)
	+ \frac{\mathrm{d} \bm{r}(t)}
	       {\mathrm{d}t}
		\Delta t
	+ \frac{1}{2}
	  \frac{\mathrm{d}^2 \bm{r}(t)}
		     {\mathrm{d}t^2}
		\Delta t^2
\end{equation}
This is approach is not time-reversible and suffers from energy drift\cite{allen1987_md}.

A mathematical process is time-reversible if the time reversed process satisfies the same dyamical equations as the original process.  The equations are invariant when $\Delta t < 0$.  Physically speaking, symmetry of the physical laws under time reversal implies the conversation of entropy.  When the numerical algorithm is not time-reversible then the energy drift is corresponds to a heat flow in or out of the system.

%In molecular dynamics, the Hamiltonian $H$ is seperable, and can be written in the form
%\begin{equation}
%	\label{eq:md_hamiltonian}
%	H(p,q) = T(p) + V(q)
%\end{equation}
%with $T$ being the kinetic energy, $V$ is the potential energy, and $(p,q)$ are canonical coordinates include both the position $q$ and $p$ momentum coordinates.  Here the Euler algorithm is a first order integrator

Instead, molecular dynamics requires the use of a numerical integrator that provide better numerical stability and provides time-reversibility.  As an example, we discuss the Verlet integration scheme\cite{verlet1967_integrator}.  While the Euler algorithm is a 1st order forward difference Taylor expansion to order one,  Verlet integration is a 2nd order central difference equation:
\begin{equation}
	\frac{\mathrm{d}^2 r(t)}
	     {\mathrm{d}t^2}
	= \frac{\bm{r}(t+\Delta t)
	          - 2\bm{r}(t)
		        + \bm{r}(t-\Delta t)}
	       {\Delta t^2}
\end{equation}
Thus,
\begin{equation}
  \frac{\bm{r}(t+\Delta t)
	      - 2\bm{r}(t)
				+ \bm{r}(t-\Delta t)}
	     {\Delta t^2}
	=
	- \frac{1}
	       {m}
		\frac{\mathrm{d} V(\bm{r}(t))}
		     {\mathrm{d} \bm{r}}
\end{equation}
\begin{equation}
	\label{eq:verlet_}
	\bm{r}(t+\Delta t)
	=
	2\bm{r}(t)
	- \bm{r}(t-\Delta t)
	- \frac{1}{m}
		\frac{\mathrm{d} V(\bm{r}(t))}
		     {\mathrm{d} \bm{r}}
		\Delta t^2
\end{equation}
Equation
\section{Empirical Interatomic Potentials}
%The interatomic potential $U(\bm{R}_i)$ derived from the Born-Oppenheimer approximation is derived from a quantum-mechanical perspective.
The computational cost of \emph{ab initio} techniques such as density functional theory (DFT)\cite{hohenberg1964_dft,kohn1965_dft} can provide accurate structural energies and forces.    \emph{Ab initio} methods are numerical methods to solve the electronic Schr\"odinger equation given the position of the nuclei $\bm{R}$ and the number of electrons.  These calculations provide useful information such as electron densities, energies, and other properties. However, the computational cost to compute $V(\bm{R}_i)$  limits DFT to either static calculations or short simulation times on systems containing a small number of atoms.
An empirical interatomic potential $\hat{V}(\bm{R}_i;\bm{\theta})$ is an analytical function parameterized by $\bm{\theta}=(\theta_1,...,\theta_n)$ which is meant to approximate $V(\bm{R}_i)$, and provide computational efficiency by eliminating electronic structure calculations.

Over the last few decades, a large number of potentials have been developed to descibe various bonding types and environments.
To take representative examples, the Lennard Jones potential\cite{lennardjones1924_lj_pot} was developed for the van der Waals interactions of noble gases, pair potentials such as the Buckingham potential\cite{buckingham1938} can be used for ionic solids\cite{catlow1977_buckingham}, the embedded atom model (EAM)\cite{daw1983_eam,daw1984_eam} was developed for metallic systems,
the Assisted Model Building with Energy Refinement (AMBER)\cite{cornell1995_potential_amber} for biomolecules, and
the Tersoff potential\cite{tersoff1988_potential_1,tersoff1988_potential_2} for covalently bonded materials.
The need to deal with bonding and chemical environments for heterogenous materials like metal/metal oxide interfaces has led to extensions such as MEAM\cite{baskes1992_potential_meam},  REBO\cite{brenner1990_potential_rebo},  COMB\cite{liang2003_potential_comb},
and ReaxFF\cite{vanduin2001_reaxff}.

The topic of empirical potentials and their development is covered in detail in Chapter \ref{ch:potential_development}.

\section{Energy Minimization}

Function optimization is a calculation that pervades much of numerical analysis.  In the context of material systems, the function to be optimized (in this case minimized) is the energy of a system.  The energy landscape of a material may posseses many minima, or conformational substates.  The goal of energy minimization is to find the local energy minimum, which is the atomic configuration corresponding to the bottom of the energy well for that phase.

Physically, energy minimization corresponds to an instantaneous freezing of the system; a static structure in which the forces between atoms have been eliminated at $0$ K.

Starting with different configuration of atoms, may lead to different energies.  Each of these energies corresponds to a different phase of the material.  The lowest energy phase corresponds to the thermodynamically stable phase at $0$ K.  Other atomic configurations are non-equilibrium phases of the material system at $0$ K which corresponds to the local minimum of that phase.

\section{Thermodynamic Ensembles}
  The statistical ensembles for molecular dynamics simulations can be defined by examination of the ideal gas law:
  \begin{equation}
  \label{eq:ideal_gas_law}
    PV = N k_B T
  \end{equation}
  where pressure ($P$), volume ($V$), and temperature ($T$), and the number of atoms ($N$) are the state variables of the system.  Each of the state variables is definable in a molecular dynamics simulation.

  The simplest state variables to obtain are the number of atoms and volume.  These are defined by the number of atoms in the simulation cell, and the volume of that unit cell.  Calculation of temperature and its regulation is discussed in Section \ref{sec:nvt_ensemble} through the use of thermostat algorithms.  Likewise, the calculation of pressure is presented with barostat algorithms in Section \ref{sec:npt_ensemble}.

  In MD simulations, it is often necessary or desireable to study a system under the conditions of constant pressure or constant temperature.  The ensembles most typically used for molecular dynamics, are the microcanonical (NVE), canonical (NVT), and isothermal-isobaric (NPT).

  In this section, the NVE is first discussed, and the other ensembles are discussed as modification of the equations of motion for the NVE ensemble.  The purpose of this section is to provide a broad overview of the topic.

Simulations of the canonical ensemble introduce the regulation of temperature.  Problems with temperature rescaling approaches are discussed.  Two types of thermostats are discussed ones involving the stochastic approach of Langevin dynamics, and the Nos\'e-Hoover thermostat\cite{hoover1985_npt} which modifies the equations of motion.

The isothermal-isobaric (NPT) introduces regulation of pressure.  The discussion here is limited to the approach of Parrinello and Rahman\cite{parrinello1981_barostat}.

\subsection{NVE}
Molecular dynamics can be written in Hamiltonian form to specifically express conserved quantities\cite{allen1987_md}, which can then be used to derive the equations of motion,
\begin{equation}
	\frac{\mathrm{d} \bm{r}}
	     {\mathrm{d} t}
	=
	\frac{\partial H(\bm{r},\bm{p})}
	     {\partial \bm{p}},
	\quad
	\frac{\mathrm{d} \bm{p}}
	     {\mathrm{d} t}
	=
	\frac{\partial H(\bm{r},\bm{p})}
	     {\partial \bm{r}}
\end{equation}

Integration of the classical equations of motion (e.g. Verlet integration) for a system leads as {$t \rightarrow \infty$} to a trajectory that produces an ensemble of microstates: the microcanonical, canonical or isenthalpic ensemble.  Without regulation of temperature or volume, a molecular dynamics simulation produces the microcanonical ensemble.

  The independent variables of the microcanonical enseble ($N$, $V$, and $E$) are extensive, which means they should be conserved during the simulation,
\begin{equation}
	\frac{\mathrm{d} H}
	     {\mathrm{d} t}
	=
	\frac{\partial H(\bm{r},\bm{p})}
	     {\partial \bm{r}} \frac{d\bm{r}}{dt}
	+
	\frac{\partial H(\bm{r},\bm{p})}
	     {\partial \bm{p}}
	\frac{\mathrm{d} \bm{p}}
	     {\mathrm{d} t}
	= 0
\end{equation}

  The other state variables are not conserved ($P$, $T$, and the chemical potential $\mu$), and should fluctuate around well-defined average values.


\subsection{NVT and Thermostats}
\label{sec:nvt_ensemble}
The microcanonical ensemble where the energy is kept constant is not often used because this does not correspond with conditions under which most experiments are performed.  Regulation of the temperature is motivated by the need to match experimental conditions and to study temperature-dependent processes,

A canonical ensemble (NVT) is the statistical ensemble that represents the possible states of a mechanical system in thermal equilibrium with a heat bath at a fixed temperature.  The principal thermodynamic variable of the canonical ensemble is temperature.  The ensemble also depends on the number of particles in the system, and the system's volume.

A modification of the Newtonian equations of motion to generate a thermodynamic ensemble at a constant temperature is a thermostat.  Thermostats in molecular dynamics provide a mechanism of regulating the simulation temperature $T_0$.  In NVT simulations, themostating modifies the translation velocity of the particles.

A short discussion of thermostats is provided here.  For a more detailed description, see H\"{u}nenberger\cite{hunenberger2005_thermostat}, Allen and Tildesley \cite{allen1987_md}, and Tadmor and Miller \cite{tadmor2011_md}

In thermostatting, the instaneous temperature $\mathcal{T}$ is compared to the temperature of the heat bath $T$ which the system is coupled to.

The equipartition theorem provides the quantitative prediction, for the average kinetic and potential energies of a system.  The equipartition theorem gives the average values of the individual components of energy.  The average kinetic energy $K$ of a system is related to its macroscopic temperature $T$ through
\begin{equation}
  K
  =
  \langle \mathcal{K} \rangle
  =
  \frac{1}
       {2}
  k_B N_{\mathrm{df}} T
\end{equation}
where $N_{\mathrm{df}}$ is the internal degrees of freedom in the system, $\mathcal{K}$ is the instantaneous internal kinetic energy, and the angular brackets indicate either a time or statistical average over the entire ensemble.
The number of internal degrees of freedom is calculated as $N_{\mathrm{df}} = 3 N - N_c$, for a system with $N$ number of atoms and $N_c$ geometrical constraints on the system.
The instanteous temperature $\mathcal{T}$ is
\begin{equation}
  \mathcal{T}
  =
  \frac{2}
       {k_B N_{\mathrm{df}}}
  \mathcal{K},
\end{equation}
then the average temperature $\langle\mathcal{T}\rangle$ is identical to the macroscopic temperature $T$.  Since the velocity $\bm{v}_i$ of each particle $i$ is obtained from Verlet integration, the instantaneous kinetic energy $\mathcal{K}$ can be replaced by the particles' momenta $\bm{p}_i$,
\begin{equation}
  \label{eq:T_kinetic_energy}
  \mathcal{T}
  = \frac{2}
         {k_B N_{\mathrm{df}}}
    \sum_{i=1}^N
		  \frac{1}{2}
		  \frac{|\bm{p}_i|^2}{m_i}
  = \frac{2}
         {k_B N_{\mathrm{df}}}
    \sum_{i=1}^N
		     \frac{1}{2} m_i |\bm{v}_i|^2
\end{equation}

\begin{equation}
  E_k
	= \langle K \rangle = \sum_{i=1}^N
	=
	\frac{1}{2} m_i |\bm{v}_i|^2
\end{equation}

\subsubsection{Velocity Rescaling}
An obvious way to regulate the temperature is velocity scaling\cite{tadmor2011_md}.  Denote the temperature at time $t$ as $T(t)$ and combine with Equation \ref{eq:T_kinetic_energy}
\begin{align}
  \Delta T(t)
  &= T(t) - T(t-1) \\
  &= \frac{1}{2}
     \sum_{i=1}^N 2 \frac{m_i (\lambda \bm{v}_i)^2}
                         {N_{\mathrm{df}} k_B}
     -
     \frac{1}{2}
     \sum_{i=1}^N 2 \frac{m_i \bm{v}_i^2}
                         {N_{\mathrm{df}} k_B} \\
  &= (\lambda^2 - 1) T(t)
\end{align}
where $\lambda = \sqrt{T/T_0}$.  Thus, the simplest way to control the temperature is to multiply the velocities at each time step by $\lambda$.

This algorithm keeps the instantaneous temperature set to exactly $T_0$.  Since this approach does not allow fluctuations in temperature, it is inconsistent with the statistical mechanics of the canonical ensemble, where we know that the kinetic energy is not constant even when a system is at thermal equilbrium with its heat bath.

Here, we discuss three thermostats for the canonical ensemble: (1) the Berendsen thermostat, (2) the Lagevin thermostat, and the (3) Nos\'e-Hoover thermostat.

\subsubsection{Berendsen thermostat}

The Berendsen thermostat\cite{berendsen1984_nvt} is an algorithm to re-scale the velocities of the particles in molecular dynamics simulations to control the simulation temperature.  Here the temperature of the system is corrected such the deviation exponentially decays with some time constant $\bm{\tau}$
\begin{equation}
  \label{eq:npt_berendsen_1}
  \frac{dT(t)}{dt} = \frac{1}{\tau} (T_0 - T(t)).
\end{equation}
The coupling parameter $\bm{\tau}$ determines how tighly the bath and the system are coupled together.  The change of motion between successive time steps is:
\begin{equation}
  \label{eq:npt_berendsen_2}
  \Delta T(t) = \frac{1}{\tau} (T_0 - T(t)) \Delta t
\end{equation}
This thermostat suppresses fluctuations in the kinetic energy of the system and therefore cannot produce trajectories consistent with the cannonical ensemble.

\subsubsection{Langevin thermostat}

In the Langevin thermostat\cite{allen1987_md}, the regulation of the temperature is maintained by transforming Newton's equation of motion into a stochastic differential equation.
The Langevin thermostat incorporates random forces into the equations of motion.  These random forces model the effect of the heat bath.

The original Langevin equation\cite{langevin1908_equation} described Brownian motion,
\begin{equation}
  \label{eq:langevin}
  m_i \frac{\mathrm{d}^2 \bm{r}_i}
	         {\mathrm{d} t^2}
  =
  - \lambda
	  \frac{\mathrm{d} \bm{r}}
	       {\mathrm{d} t}
	+ \bm{\eta}(t).
\end{equation}
The force acting on the article is written as a sum of a viscous force proportional to the particle's velocity (from Stokes' law), and a stochastic term $\bm{\eta}(t)$, which has a Gaussian probability distribution is correlation function usually expressed as
\begin{equation}
  \label{eq:langevin_eta}
  \langle \eta_i(t) \eta_j(t') \rangle = 2 \lambda k_B T_0 \delta_{ij} \delta(t-t'),
\end{equation}
where $\eta_i$ is the $i$th component on the vector $\eta_i(t)$.  Equation \ref{eq:langevin_eta} is described in terms of an autocorrelation function to mathematically describe Brownian motion.

A description from Brownian motion using probability theory notation\cite{karatzas1991_sde} is clearer than Equation \ref{eq:langevin_eta}. Denote $B(t)$ as a standard Brownian motion, then $B(t)$ has independent increments with respect to time $t$.  For every $t > 0$, the future increments $B(t+\Delta t) - B(t)$, for $u \geq 0$, are independent of the past values $B(s)$, $s < t$.  Brownian motion has Gaussian increments $B_{t+\delta t}-B_{t}$ with mean $0$ and variance $\delta t$; $B_{t+\delta t}-B_{t}~N(0,\delta t)$.
Finally, $B(t)$ has continuous paths and is continuous in $t$.
Since $B(t)$ is nowhere differentiable, the stochastic differential $\mathrm{d}B(t)$ informally denotes the corresponding It\^{o} integral
\begin{equation}
  B(t+\delta t) - B(t)
	=
	\int_t^{t+\delta{t}} \!\!\! \mathrm{d}B(\tau),
\end{equation}
and then $\mathrm{d} B(t)/\mathrm{d}t$ denotes a white noise process.

With this description, $\bm{\eta}(t)$ is based on the evolution of a standard Brownian motion,
\begin{equation}
  \bm{\eta}(t) = \sigma \frac{d\bm{B}(t)}{dt}
\end{equation}
rescaled by $\sigma^2 = 2 m_i \lambda_i k_B T_0$, and $\bm{B}(t) \in \mathbb{R}^3$ with $B_i(t)$ independent from $B_j(t)$ for $i \neq j$.  Then $\bm{\eta}(t)$ models the heat flow from a solvent at a constant temperature $T_0$.  The necessary properties implied by Equation \ref{eq:langevin_eta} follow immediately from the definition of standard Brownian motion.

The Langevin thermostat\cite{grest1986_langevin} was originally developed to explain the interaction of the solvent (i.e. the heat bath) on the solute (i.e. the simulated system) and has two levels of interaction.  First, the atoms interact with each other through the interatomic potential.  Second, the atoms are in constant collision with some medium that constitutes the heat bath, with the assumption that interactions with the heat bath are more frequent and exert smaller forces than the interatomic iteraction.  This allows the  interatomic interactions to be decoupled from the interactions from the heat bath.  Adding the terms from Equation \ref{eq:langevin} to the Newton's equation of motion, we get the new governing equation for atom $i$.
\begin{equation}
  \label{eq:langevin_eos}
  \frac{\mathrm{d}^2 \bm{r}_i}
	     {\mathrm{d} t^2}
  =
  \frac{1}{m_i} \bm{f}_i
  - \frac{\gamma}
	       {m_i}
	  \frac{\mathrm{d} \bm{r}_i}
		     {\mathrm{d} t}
  + \frac{1}{m_i} \bm{\eta}_i(t)
\end{equation}
where $\gamma$ is now dampening constant associated with atom $i$.

In the Langevin thermostat, the choice of $\gamma$ becomes arbitrary.  The choice of too small of $\gamma$ leads to slow equilbrium, while a large value of the dampening constant leads to the stochastic term dominating the equations of motion.

\subsubsection{Nos\'e-Hoover thermostat}
% https://www2.mpip-mainz.mpg.de/~andrienk/journal_club/thermostats.pdf
The method to specify the temperature in a molecular dynamics simulation was proposed by Nos\'e\cite{nose1984_npt_1,nose1984_npt_2}.  In this approach, Nos\'e proposed an extended form of the Hamiltonian which introduces a fictitious particle, which couples the system to the heath bath.  The Nos\'e equations of motion are smooth, deterministic, and time-reversible, but stretched the timescale making them impractical for simulation purposes.  These equations were refined by Hoover\cite{hoover1985_npt} to reformulate Nos\'e equations in term of real system variables.  This formulation is known as as the Nos\'e-Hoover thermostat.

The Langrangian equations of motion for the Nos\'e-Hoover thermostat are
\begin{equation}
  \label{eq:nose_hoover_1}
  \frac{\mathrm{d}^2 \bm{r} }
       {\mathrm{d} t^2 }
  =
  \frac{\bm{f}_i}
	     {m_i}
	- \gamma \bm{r_i},
\end{equation}
with
\begin{equation}
  \label{eq:nose_hoover_2}
  \frac{d\gamma}{dt}
  =
  \frac{1}{M}
   \left(
       T(t) - N_{\mathrm{df}} k_B T_0
   \right)
\end{equation}

Equation \ref{eq:nose_hoover_1} is similar to the Langevin thermostat but without the stochastic term.  Since the time-evolution is described by a second order differential equation, the heat may flow to and from the system causing oscillations in the system. Equation \ref{eq:nose_hoover_2} provides the feedback between the $\mathcal{T}$ and $T_0$.

The Nos\'e-Hoover thermostat has one free parameter $M$ which is the mass of the ficticious particle.  This mass serves as mechanism to control the oscillations in the system, as a large $M$ will provide a large inertia and make heat flow between the heat bath and the simulated system sluggish.  If the mass is too small, the thermostat will not control the temperature adequately.

Since the equations of motion have changed, the Verlet integration scheme needs to be modified.

\subsection{NPT and Barostats}
\label{sec:npt_ensemble}
In the isothermal-isobaric (NPT) ensemble, the pressure has a specified average value, while the instantaneous volume $\mathcal{V}$ of the system can fluctuate.

The usual approach for the evaluation of pressure $P$ in an MD simulation involves an ensemble average of the instataneous pressure $\mathcal{P}$\cite{allen1987_md}.  For a system with $N$ atoms in a volume $\mathcal{V}$, the instantaneous pressure can be defined as the contributions of each atom $i$
\begin{equation}
  \mathcal{P}
  =
  \frac{1}{\mathcal{V}}
  \left(
    \frac{1}{3}
    \sum_{i=1}^N m_i \bm{v}_i  \cdot \bm{v}_i
    +
    \frac{1}{3}
    \sum_{i=1}^N \bm{r}_i \cdot \bm{F}_i
  \right)
\end{equation}

For a system with interactions, the pressure can be written as a virial equation\cite{tadmor2011_md}
\begin{equation}
  \label{eq:virial_equation}
  P
	=
	\left\langle
	  \frac{N k_B \mathcal{T}}{\mathcal{V}}
  \right\rangle
  +
	\left\langle
	  \frac{1}
		     {3\mathcal{V}}
    \sum_{i=1}^N
        \bm{r}_i \cdot \bm{F}_{i}
	\right\rangle
\end{equation}
The first term of the right hand side of Equation \ref{eq:virial_equation} is the kinetic contribution and the second term is the Clausias virial function modeling residual contribution arising from atoms interacting through the potential $V$.  Since all quantities needed to calculate pressure are easily acessible in an MD simulation, Equation \ref{eq:virial_equation} can be used to calculate pressure.  The macroscopic pressure $P$ is simply obtained as $P=\langle \mathcal{P} \rangle$.

The Parrinello-Rahman barostat\cite{parrinello1980_barostat,parrinello1981_barostat} allows the size and the shape of the simulation cell to vary in time as a result of the difference between varying the internal microscopic stress tensor and the constant external stress tensor $\bm{\omega}$.  The simulation cell is characterized by the tensor $\bm{H}=(\bm{a}_1,\bm{a}_2,\bm{a}_3) \in \mathbb{R}^{3 \times 3}$, where $\bm{a}_1$, $\bm{a}_2$, and $\bm{a}_3$, are the lattice vectors of the simulation cell.

The discussion provided here follows the exposition by Ray and Rahman\cite{ray1984_npt}.  The Parrinello-Rahman equations of motion can be derived from the Hamiltonian from the coordinate system $(\bm{r},\bm{p})$ to the canonical variables $\hat{\bm{r}},\hat{\bm{p}}$, which incorporates $\bm{H}$,
\begin{equation}
  \hat{\bm{r}}_i = \bm{H}^{-1} \bm{r}.
\end{equation}
$\hat{\bm{r}}_i$ is a position vector in fractional coordinates defined by $\bm{H}$.
\begin{equation}
  \hat{\bm{p}}_i = \bm{H}^T \bm{p}_i
\end{equation}
This allows the box to deform in response to an applied stress, so that the equilibrium shape of the box corresponds to the state where the internal stress is equal to the imposed stress.

Parrinello and Rahman defines an extended form of the Hamiltonian which adds the potential energy and kinetic energy associated with the shape of the simulation cell $\bm{H}$, which adds the potential energy due to deformation of the simulation cell and kinetic energy of the box.  The kinetic energy of the box is a ficticious construct which allows the modification of $\bm{H}$ so that simulation cell is in equilibrium with the external stress tensor.

Since the pressure includes a kinetic component due to particle velocities, barostatting requires regulation of both temperature and pressure.
The Parrinello-Rahman equations can be combined with thermostats to then generate the NPT ensemble\cite{shinoda2004_nosehoover} and can then be integrated\cite{tuckerman2006_timeintegrator}.

%Which produces the following Lagrangian from which the equations of motion can be derived.

%\begin{equation}
%  \mathcal{L}
%  \left(\hat{\bm{r}},
%    \bm{H},
%    \frac{d\bm{\hat{r}}}
%         {dt}
%    \frac{d\bm{H}}{dt}
%  \right)
%  =
%  \frac{1}{2}
%  \sum_{i=1}{N}
%      m_i
%      \left(
%				\frac{d \bm{\hat{r}} }
%             {dt}
%      \right)^T
%      \bm{G}
%      \left(
%				\frac{d \bm{\hat{r}} }
%             {dt}
%      \right)
%  - V(\bm{r},\bm{H})
%  + \frac{1}{2}
%    W
%    \mathrm{tr}\left(
%      \left(\frac{d\bm{H}}{dt}\right)^T
%      \left(\frac{d\bm{H}}{dt}\right)
%    \right)
%  - \sigma \mathcal(V).
%\%end{equation}
%Here, $\bm{G}=\bm{H}^T\bm{H}$ and $\bm{W}$ is a constant with the dimensionality of weight that serves as a dampening parameter.
