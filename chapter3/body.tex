\chapter{A PARETO APPROACH TO PARAMETER OPTIMIZATION}

In the previous chapter, an overview of the different computational tools associated to atomistic simulation were presented to give some idea of interconnectivity and breath of atomistic simulations.  Within this chapter, we outline the Pareto approach to potential optimization within the context of more typical current appraoches to potential development.

The structure of this chapter starts off by framing potential development the broadest mathematical framework possible since the purpose of this dissertation is to identify new techniques and directions for potential development which have been enabled by a broad set of computational tools which harnesses large amounts of computational power to solve analytically intractable problems in a field broadly known as machine learning.  We introduce potential development as a surrogate model for the true potential energy surface.

\section{Potential Energy Surfaces}

The potential enrgy surface is the energy of a collection of atoms as a function of the positions of its nuclei, ${R}$.  Using the analogy of a landscape, the potential energy surface.  The PES represents a mapping of the positions of the atoms of a material system to an energies.  This creates an energy landscape which allows materials systems to viewed from a topological perspective, which allows the PES to describe the evolution of a system.

In solid materials, atoms are typically represented as infinite crystalline solids, with th atomic positions placed within a representative cell unit.  The representative cell unit is describe by the three lattice vectors which define the boundaries of the representative cell, and periodic boundaries conditions applied to reflect the translational symmetry of crystalline systems.

Given $r$, $V(\bm{R})$ gives the height of the energy landscape for any atomic configuration, providing an analytical approximation of the potential energy surface, so that the concept of a potential energy surface arises.  To study the evolution of a system, such as kinetic properties and chemical reactions, it is necessary to calculate the energy for every atomic arrangement of interest.

Many decision and plannning problems involve multiple conflicting criteria which must be considered simultaneously.  In the field of optimization, problems which have multiple criteria are deferred to as multiple critieria decision making problems (MCDM) and the algorithms used to solve them as multiple-objective optimization (MOO).  Here the set of feasible solutons is not known in advance, but is restricted by constraint functions.  We concentrate on nonlinear multiobjective optimization and ignore approaches designed for multiobjective linear programming.

\section{Interatomic Potentials as a Surrgoate Model}
The goal of developing a interatomic potential is identify a computationally efficient surrogate model, which models the potential energy surface.

\begin{equation}
  V(\bm{R}) = \hat{V}(\bm{R}) + \epsilon(\bm{R})
\end{equation}

Here $V$ is the true potential energy surface which is approximated by our potential model $\hat{V}$, which is a function the representation of a collection of atomic positions, $R$.  Since energy is a scalar value, the difference between the potential energy surface we will refer to as the error function, $\epsilon(\bm{R})$.


The geometry of a molecule can be described by the collection of the positions of $N$ atoms $\bm{R} = \{\bm{r}_1,...,\bm{r}_N\}$, where the $\bm{r}_i$ could be the set of Cartesian coordinates of the atoms.  These collections of atoms can be transformed to reflect the distances between atom, $\bm{r}_{ij}=\bm{r}_i - \b{r}_j$ as used in pair potentials, the angles between atoms $\bm{r}_{ijk}$ as in three body potentials.

Additionally, the approach described within this chapter is described briefly and is followed on by more detailed discussions and application in following chapters and appendices.  The emphasis of the development of this methdology will be on the mathematical aspects of the subject and it's applications to the development of classical empirical potentials.  The intent is to provide tools for a decision maker, rather than to convince which particular optimization to use.

Secondly, another purpose of the development of this methdology is the development of parameterizations which can be expressed as an ensemble of potentials described as a probability distribution function which can be used in UQ propogation.

\section{Multiobjective optimization}

The general multi-objection optimization problem using the notation of Marler and Arora\cite{Marler2004_moo_survey}:
%\begin{equation}
\begin{align}
  & \underset{\bm{x}}{\text{minimize}}
        &\bm{F}(\bm{x}) = [ F_1(\bm{x}),
                            F_2(\bm{x}),
                            ...,
                            F_k(\bm{x})]^T\\
  & \text{subject to}
        &g_j(\bm{x}) \leq 0, j=1,2,...,m \\
  &     &h_l(\bm{x}) = 0, l=,1,2,...,e \\
  &     &\bm{x} \in \bm{X}
\end{align}
%\end{equation}
where $k$ is the number of objective functions, $m$ is the number of inequality constraints, and $e$ is the number of equality constraints.
The vector $\bm{x} \in \bm{X} \subseteq \mathbb{R}^n$ is a vector design variables $x_i$, and $X$ is feasible design space.
$\bm{F}(\bm{x}) \in \mathbb{R}^k$
are called objectives, cost functions, or criteria.  The feasible critereon space $Z$ is defined as
$\{\bm{F}(\bm{x}) | \bm{x} \in \bm{X} \}$.

For MOOs, the objectives are generally conflicting, preventing simultaneous optimization.

\subsection{Pareto optimality}

If all functions are for minimization, a feasible solution $\bm{x}_1$ is said to dominate another feasible solution $\bm{x}_2$, denoted $\bm{F}(\bm{x}_1 \succ \bm{x}_2)$, if and only if $F_i(\bm{x}_1)\leq F_i(\bm{x}_2)$ for $i = 1,...,k$ and $F_j(\bm{x}_1)< F_j(\bm{x}_2$) for at least one objective function $j$.  A solution is said to be Pareto optimal if it is not dominated by any other solution in the solution space.  A Pareto optimal solution cannot be improved with respect to any objective without worsening at least one objective function.  The set of all feasible non-dominated solutions in $X$ is referred to as the Pareto optimal set, and for a given Pareto optimal set, the corresponding values in the objective space are called the Pareto Front.

\section{Parameter Estimation as a Multiobjective Optimization Problem}
Parameter estimation can be stated as a MOO problem.
While this is occasionally stated in potential development literature, it is often within the context of the use of global optimization techniques.
The purpose of this section is provide a clear methodological approach to determining the optimal parameters within the context of MOO, and elucidate the problems often encountered in potential development specifically to the choice of optimization techniques often employed in potential development.

Let $V(r_{ij},\bm{\theta})$ be an analytical potential, dependent upon the distance, $r_{ij}$, between atoms $i$ and $j$; the parameters of the potential are defined by the array $\bm{\theta}=(\theta_1,...,\theta_P)$ for $P$ parameters.
Then to calculate material properties, the potential is combined with the structures and the necessary simulation conditions, such as temperature, pressure, and volume.
Since there is a difference between the predicted material properties which a potential predicts and the actual material properties, it is necessary to introduce notation to differentiate the two.
The predicted material properties will be denoted by $\hat{\bm{q}} = (\hat{q}_1,...,\hat{q}_M)$, while the actual material property will be denoted by $\bm{q} = (q_1,...,q_M)$ for $M$ structural properties.  The notation of $q$ comes from verification, validation, and uncertainty quantification literature where the term quantity of interest (QOI) is used.

Then for the purposes potential development, a potential can than be viewed as a function $V:\bm{\Theta} \rightarrow \hat{\bm{Q}}$ where the parameters $\bm{\theta} \in \bm{\Theta}$ maps to $\hat{\bm{q}} \in \hat{\bm{Q}}$.
Since $\hat{\bm{q}}$ is a function of of the potential $V$, then we denote this relationship
$\hat{\bm{q}}(\bm{\theta})$ and
$\hat{\bm{Q}}(\bm{\theta})$.



\subsection{Fitting Database}
A fitting database is a collection of structure property functions $q_i$ with an associated atomic configurations, also referred to as structures.
The set of all possible atomic configuration is referred to as the configuration space.
The goal of a fitting database to find to find a representative set of structures in which to calculate the structure property relationships $q_i$.

Lattice constant, bulk modulus, vacancy formation energy, or anything that can be defined from energy structures.  In the fitting database, the structure proerty functions evaluated using an empirical potentials and compared to target reference values, with values either determined from experimental values or a a high-fidelity structure such as DFT.  The collection of structure property relationships, is denoted $\bm{q}=(q_1,q_2,...q_N)$ for $N$ structure property relationships.  Usually accuracy and transferribility are tested against an external database.

In literature, the developers of potentials tend to use $0$ K properties.  A more important reason why potentials are fit to $0$ K properties, is that it alows the incorporation of first-principles data.
The most ubiquitous \emph{ab initio} techniques are calculations using density functional theory (DFT).
DFT allows the calculation of structural properties which are experimentally difficult to access, as well as provide energic information from kinetically unstable structures.
The incorporation of first-principles data in the fitting database significantly improves the reliability of semi-empirical potentials by sampling a larger area of configuration space[21-28].
This is covered in detail in a review article by Payne \emph{et al}\cite{payne1996_dft_database}.


Ercolessi F, Adams JB. Europhys Lett 1994;26:583.
Mishin Y, Farkas D, Mehl MJ, Papaconstantopoulos DA. Phys Rev B 1999;59:3393
Baskes MI, Asta M, Srinivasan SG. Philos Mag A 2001;81:991
Mishin Y, Mehl MJ, Papaconstantopoulos DA, Voter AF, Kress JD. Phys Rev B 2001;63:224106
Mishin Y, Mehl MJ, Papaconstantopoulos DA. Phys Rev B 2002;65:224114
Li Y, Siegel DJ, Adams JB, Liu XY. Phys Rev B 2003;67:125101
Zope RR, Mishin Y. Phys Rev B 2003;68:024102
Mishin Y. Acta Mater 2004;52:1451

From a computational standpoint, at $0$ K the calculation of material properties become precise because atomic motion stops, and only a single evaluation of a parameterization needs to be evaluated against the reference value.  When the $T>0$, issues with sampling arise.  In the long time limit, the sampled trajectory yields detailed information about the Hamiltonian.  Shorter trajectories yield incomplete information and confound comparison of parameters with experimental values.

When many $\hat{\bm{q}}(\theta)$ has to be evaluated many times, fitting to structure property relationships which are dependent upon themodynamic ensembles for $T>0$ becomes quickly computational infeasible.

\subsection{Prediction Error function}
In order to assess the prediction errors of the structure property functions, we denote the
      $\hat{\bm{q}}(\bm{\theta})=(
          \hat{q}_1(\bm{\theta}),
          \hat{q}_2(\bm{\theta}),
          ...,
          \hat{q}_N(\bm{\theta}))$
    as the predicted material properties

The difference between the prediction values and target values of the QOIs produces a vector of error functions, $\bm{\epsilon}(\bm{\theta})=(
        \hat{q}_1(\bm{\theta})-q_1,
        \hat{q}_2(\bm{\theta})-q_2,
        ...,
        \hat{q}_N(\bm{\theta})-q_N)$,
\subsection{Parameters}
Let $V$ be an empirical potential parameterized by $P$ number of parameters $\bm{\theta}=[\theta_1,\theta_2,...\theta_P]$.
\subsection{Constraints on parameters}
\subsection{Structure Property Relationships}
\subsection{Constraints on structure property relationships}

\subsection{Parameter Optimization Problem as MOO formulation}
DEFINITION OF CONFIGURATION SPACE


\section{Pareto Front}

In multiobjective optimization problems, it is characteristic that no unique solution exists, but a set of mathematically equally good solutions can be identified.  These solutions are known as nondominated, efficient, noninferior or Pareto optimal solutions.  In MCDM literature, these terms are synomous.

In MCDM literature, the idea of solving a multiobjective optimization problem is understood as helping a human decision maker (DM) in understanding the multiple objectives simultaneously and finding a Pareto optimal solution.  Thus, the solution process requires some interaction with the DM in the form of specifying preference information and the final solution is determined by these preferences.

In potential development, the preferences of potential developer likewise influences are particular parameterization, which has results in the development of empirical potentials as somewhat of a black art.  In the end, empirical potentials are simplified models which predict structure property relationships.

In classical potential optimization, the identification of an optimal parameterization is determined by the minimization of a cost function which couples multiple objective functions, usually a weighted sum of squares, and different weights are used in an interactive fashion until an acceptable parameterization is determined.
\section{Surveys of Methods}
Chankong and Haimes 1983
Hwang and Masud 1979
Marler and Arora 2004
Miettinen 1999
Sawaragi et al 1985
Steuer 1987
Vincke 1992

We start our review of methods using Hwang and Masud 1979 and Miettinen 199, to classify the different classes of approaches by methological approach rather than technical techniques.
\subsection{no preference methods}
The task is to find some neutral compromise solution without any additional information.  This means instead of asking the DM for preference information, some assumption are made about what a reasonable compromise could be like.
\subsection{\emph{a priori} methods}
In \emph{a priori}, the DM first articulates preference information and the solution tries to find a Pareto optimal solution satisfying them as well as possible.

\subsection{\emph{a posteriori} methods}
A representation of a set of Pareto optimal solution is first generated and then the DM is supposed to select the most preferred one among them.  This approach gives the DM an overview of different solutions available but if there are more than two objectives in the problem, it may be difficult for the DM to analyze the large amount of information.

\subsection{Interactive methods}
After each iteration, some information is provided to the DM in order to specify preference information.  What is noteworthy is that the DM can specify and adjust one's preferences between each iteration and at the same time learn about interdepencies between each iteration and at the same time learn about interdependencies in the problem as well as one's own preferences.
\section{Solution Methods}
MOO solution methods fall under the category of scalarization or non-scalarization methods.  Scalarization is the primary method for MOO problems [Miettinen 1999].  Scalarization converts the MOO problem into a paramterized single-objective problem which can be solved using using well-established single-objective optimization methods.
\subsection{Scalarization Methods}
\subsubsection{Weighting Method}
\subsection{Cost Function}
\begin{equation}
  C(\bm{\theta})=\sum w_i (\hat{q}_i(\bm{\theta})-q_i)^2
\end{equation}

Gass and Saaty 1955
Zadeh 1963

For a interatomic potential being fit with respect to $k$ quantities of interest,
\begin{equation}
  \begin{aligned}
  & \underset{\bm{\theta}}{\text{minimize}}
        & & \sum_{i=1}^{k}w_{i} \varepsilon_i^2(\bm{\theta}) \\
  & \text{subject to}
        & & \bm{\theta} \in \bm{\Theta}
  \end{aligned}
\end{equation}
where $w_i \geq 0$ for $i=1,...,k$
Weakly Pareto optimal.

  In the development of interatomic potentials, the DM is asked to specify weights in which case the method is used as an \emph{a priori} method.

Algorithms for multiobjective optimization should produce Pareto optimal solutions, and that any Pareto optimal solution can be found.  Censor1977 discusses the conditions which the whole Pareto set can be generated by the weighting metho when positive weights are presented.  In this respect, the weighting method has a serious shortcoming.  Any Pareto optimal solution can be found by altering weights only if the problem is convex.  Some Pareto optimal solutions of nonconvex problems cannot be found regardless of how the weights are selected.

The problems of the weighting schemes have ben explored by the classical potential development community.  The method may jump from one vertex to anohter vertex leaving intermediate solutions undetected with relatively small changes in the weighting schemes.

Scaling of the objective functions.

The weighting method can be used as an \emph{a posteriori} method where different weight can be used to generate different Pareto optimal solutions, and then the DM selects the most satisfactory solution.  Systemic methods of perturbing the weights to obatain different Pareto optimal solutions are suggested (Chankong and Haimes 1983), but Das and Dennis 1997 illustrates that an evenly distributed set of weights does not necessarily produce an evenly distributed representation of the Pareto optimal set, even when the problem is convex.

When the weighting scheme is used as an \emph{a priori} method, the DM is expected to represent his/her preferences in the form of weights.  Roy and Mousseau (1996) suggests that the role of weights in expressing preferences maybe mis leading.  Although the relative importance of weights show the relative importance of the objective functions it is not clear what underlies this notion.  The relative importance of objective functions is usually understood globally, for the entire decision problem, while many practical applications show that the importannce typically varies for different objective function values, that is, the concept is only meaningful locally. (Podinovsky 1994).

Weights that produce a certain Pareto optimal solution are not necessarily unique, and different weights may produce similar solutions.  On the other hand, a small change in weights may cause big differences in the objective function.  It is not easy for the potential developer to control the solution process because weights behave in an indirect way.  The solution process then becomes an interactive one where the DM trues to guess such weights that would produce a satisfactory solution, and this is not desirable because the DM cannot be properly suppported which leads to frustation complications in potential development.  Instead, in such cases it is advisable to use real interactive methods where the DM can better control the solution process with more intuitive preference information.

The weighting method is also difficult
%https://books.google.com/books?id=NHZqCQAAQBAJ&pg=PA1&source=gbs_toc_r&cad=4#v=onepage&q&f=false

\section{Optimization Methods}

\begin{equation}
  \begin{aligned}
  & \underset{\bm{x}}{\text{minimize}}
        & &  f(x)\\
  & \text{subject to}
        & & g_i(x) \leq 0
        & & h_j(x) = 0
        & & x \in X
  \end{aligned}
\end{equation}
here $x$ is the optimization variable, $f$ is the objective function, $g_i$ are inequality constraints, and $h_j$ are equality constraint functions.

\subsection{Convex Optimization}
Numerical algorithms make heavy use of scalarization results, and most papers in the field of MOO and economics deal with non-linear programming problems, corresponding duality theorems, and the repeated application of the simplex method.

However, within the literature of potential development approaches focus upon local minimization techniques and global optimization techniques.

objective function is concave.  constraint set is convex.  KKT requirements for uniqueness.

\subsection{Global Approaches}

Genetic algorithms are a popular meta-heuristic that is particularly well-suited for this class of problems.  Traditional GA are customized to accomodate multi-objective problems by using specialized fitness functions and introducing methods to promote solution diversity.

The second general approach is to determine an entire Pareto optimal solution set or a representative subset. A Pareto optimal set is a set of solutions that are nondominated with respect to each other. While moving from one Pareto solution to another, there is always a certain amount of sacrifice in one objective(s) to achieve a certain amount of gain in the other(s). Pareto optimal solution sets are often preferred to single solutions because they can be practical when considering real-life problems since the final solution of the decision-maker is always a trade-off. Pareto optimal sets can be of varied sizes, but the size of the Pareto set usually increases with the increase in the number of objectives.

The ultimate goal of a multi-objective optimization algorithm is to identify solution in the Pareto optimal set.  However, identifiying the entire Pareto optimal set, for multi-objective problems, is impossible to its size.  Proof of solution optimality is computationally infeasible.  Therefore, a practical approach is achieve successively better approximations of the Pareto surface that represent the Pareto set as well as possible.

A multi-objective optimization approach should achieve the following conflicting goals as described by Zitzler \emph{et al}\cite{zitzler2000_moo_evolve}: (1) the best known Pareto front should be as close as possible to the true Pareto front.  Ideally, the best-known Pareto set should be a subset of the Pareto set, (2) solutions in the best known Pareto set should be uniformly distributed and diverse over the Pareto front in order to provide the decision-maker a true picture of trade-offs, and (3) the best-known Pareto front should capture the whole spectrum of the Pareto front at the extreme ends of the spectrum.  While the first two goals are important for multi-objective optimization, the last goal is erroneous.  In general, when developing potentials, the DM is interested in compromise solutions and a parameterization with high fidelity with respect to one material property at the expense of a loss of fidelity with respect to all other prediction would be a pathological parameterization.

\subsubsection{Genetic Algorithms}
The method which will be proposed in chapter 5 is not a genetic algorithm, but has many similarities as Genetic Algorithms but tailored to create an ensemble of Pareto optimal parameters.  However, it is a genetic solution and the iterative approach of generating new populations is akin to previous solutions.  As a result, the section of review in this section is necessarily incomplete but refer to an introductory review by Konak \emph{et al}\cite{Konak2006_moo_ga} as well as the book by Deb\cite{deb2001_moo_ga}

The concept of genetic algorithms were inspired by evolutionist theories explaining the origin of species\cite{holland1992_ga}.  In nature, weak and unfit speicies within their environment are faced with extinction by natural selection, while strong ones pass on their genes to future generations through reproduction.  In the long run, species carrying the correct combinatioon in their
    genes become dominant in their population.

In GA terminology, a solution vector $\bm{x}\in\bm{X}$ is called an individual or a chromosome.  Chromosomes are made of descrete units called genes.  Each gene controls on or more features of the chromosome.  Normally, a chromosome corresponds to a unique solution $\bm{x}$ in the solution space.  This requires a mapping mechanism between the solution space and chromosome.  GA operates with a collection of chromosomes, called a population.  As the search evolves, the poulation includes fitter and fitter positions, eventually it converges, meaning that it is dominated by a single solution.  Two operators are defined crossover and mutation.  In the crossover operator, two parent solutions are combined togehter to form offspring.  The mutation operator introduces random changes into the population.

The first multi-objective GA, called vector evaluated GA (or VEGA), was proposed by Schaffer [5]. Afterwards, several multi-objective evolutionary algorithms were developed including Multi-objective Genetic Algorithm (MOGA) [6], Niched Pareto Genetic Algorithm (NPGA) [7], Weight-based Genetic Algorithm (WBGA) [8], Random Weighted Genetic Algorithm (RWGA)[9], Nondominated Sorting Genetic Algorithm (NSGA) [10], Strength Pareto Evolutionary Algorithm (SPEA) [11], improved SPEA (SPEA2) [12], Pareto-Archived Evolution Strategy (PAES) [13], Pareto Envelope-based Selection Algorithm (PESA) [14], Region-based Selection in Evolutionary Multiobjective Optimization (PESA-II) [15], Fast Non-dominated Sorting Genetic Algorithm (NSGA-II) [16], Multi-objective Evolutionary Algorithm (MEA) [17], Micro-GA [18], Rank-Density Based Genetic Algorithm (RDGA) [19], and Dynamic Multi-objective Evolutionary Algorithm (DMOEA) [20]. Note that although there are many variations of multi-objective GA in the literature, these cited GA are well-known and credible algorithms that have been used in many applications and their performances were tested in several comparative studies.



\emph{Vector Evaluated Genetic Algorithm (VEGA)}.  Schaffer proposed VEGA for finding multiple solutions to multiobjective problems.  He created VEGA to find and maintain multiple classification rules in a set covering problem.  VEGA tried to achieve this goal by selecting a fraction of the next generation using one of the objective functions.

Fitness Sharing encourage the search in unexplored section of a Pareto front by artificially thinning solutions in densely populated area.  To achieve this goal, densely populated areas are identified and a penalty method is used to penalize the solutions located in such areas.  This approach was recommended by Goldberg and Richardson\cite{goldberg1987genetic} and used by Fonseca and Fleming\cite{fonseca1993multiobjective} to penalize clustered solutions.
\begin{equation}
    dz(\bm{x}_1,\bm{x}_2)
    = \sqrt{\sum_{k=1}^{K}  \left(\frac{z_k(\bm{x_1})-z_k(\bm{x_2})}
                                       {z_{k}^{max}-z_{k}^{min}}
                            \right)^{2}
      }
\end{equation}

based on these distances, calculate a niche count for each solution $\bm{x}\in\bm{X}$ as
\begin{equation}
  nc(\bm{x}_1,t)=\sum_{\bm{x}_2\in\bm{X},r(\bm{x}_2,t)=r(\bm{x}_1,t)}
      \max\left\{ \frac{\sigma_{share}-dz(\bm{x}_1,\bm{x}_2)}
                       {\sigma_{share}},0
          \right\}
\end{equation}
where $\sigma_{share}$ is the niche size by defining a neighborhood of solutions in the objective space.  Solutions in the same neighborhood contribute to each other's nich count.  Therefore, a solution in a crowded neighborhood will have a higher niche count, reducing the probability of selecting that solution from being culled from the survivor set.

\section{Visualization}
This problem is dealt with in discussions about visualization and and analysis of the large amounts of data generated from a posteriori approaches to solving these problems.
Edgeworth 1881
Koopmans 1951
Kuhn Tucker 1951
Pareto 1896, 1906
\section{Treatment}

Our treatment of the mapping of the empirical potential is treated as a bijective mapping into two measure spaces.

Let us define parameter space with the probability measure space $(\Theta,\mathcal{F}(\Theta),\mathbb{P})$.

Then we define the error space of the structure property relationships with the probability measure space $(\mathcal{E},\mathcal{F}(\mathcal{E})),\mathbb{Q})$.


To solve forward problems, the parameters of a potential, $\bm{\theta}$ is known \emph{a priori}, are used in conjunction of a set of atomic arrangements in a simulation cell with periodic boundary conditions to predict $n$ material properties, $\bm{q} = (q_1,...q_n)$.  These predictions depend not only on the atomic arrangements but also on the parameterization, denoted
$\bm{\hat{q}}(\bm{\theta}) =
    (\hat{q}_1(\bm{\theta}),...\hat{q}_n(\bm{\theta}))$.
The differences between the predicted values and references values are denoted
$\bm{\epsilon}(\bm{\theta}) =
    \lvert \bm{\hat{q}}(\bm{\theta})
         - \bm{q}_i
    \rvert$,
where $|\bm{x}|$ is the elementwise magnitude of the vector $\bm{x}$.

The problem of parameterization is an inverse problem where an optimal parameterization produces ideal outcomes for the forward problem, i.e. difference between the predicted value and the reference value,
$\epsilon_i(\bm{\theta}) = 0$.
Since replication of results is typically not achievable, then the goal of parameterization becomes
$\min_{\bm{\theta}} \epsilon_i(\bm{\theta})$
for all $i$.  Typically, there does not exist an optimal parameterization, $\bm{\theta}^*$, which minimizes $\epsilon_i(\bm{\theta})$ for all $i < n$.  Requiring a prioritization of which material properties have a preference for fidelity in predictions.

The typical approach to solving the inverse problem transforms the above problem into a scalar optimization problem amenable to derivative approaches.  A cost function $C$ which couples the individual objectives, $\epsilon_i$, along with a set of weights $\bm{w} = (w_1,...,w_n)$, to represent preferences, that is
\begin{equation}
    C(\bm{\theta}) = \sum_i^n w_i (\hat{q}_i(\bm{\theta}) - q_i)^2
                   = \sum_i^n w_i \epsilon_i^2(\bm{\theta})
\end{equation}

It is clear that the selection of $\bm{w}$ uniquely determines $\bm{\theta}^*$.  However, the values of $w_i$ which will produce an acceptable potential are typically not known \emph{a priori}.  When the initial weighting scheme fails to give an acceptable results, $\bm{w}$ is changed in an \emph{ad hoc} approach until an acceptable parameterization is achieved.

Since analytical solutions are intractable, numerical solutions are achieved by selecting an initial parameterization, $\bm{\theta}_0$, and using derivative-based optimization techniques to minimize the cost function.  If the $C(\bm{\theta})$

We generalize the problem of parameter estimation by a casting it more generally into a multi-objective optimization problem:
\begin{equation}
    \min_{\bm{\theta}} \bm{\epsilon}(\bm{\theta})
        = \begin{bmatrix}
            \epsilon_1(\bm{\theta}) \\
            \vdots \\
            \epsilon_n(\bm{\theta})
          \end{bmatrix}
        = \begin{bmatrix}
            \hat{q}_1(\bm{\theta}) - q_1 \\
            \vdots \\
            \hat{q}_n(\bm{\theta}) - q_n
          \end{bmatrix}
\end{equation}

To remove the dependence on \emph{a priori} performance preferences, it is necessary to define an ensemble of parameterization which are optimal in a sense.  Suppose we have two parameterizations, where $\bm{\theta}_1$ dominates $\bm{\theta}_2$, denoted $\bm{\theta}_1 \prec \bm{\theta}_2$, when $\epsilon_i(\bm{\theta}_1) \leq \epsilon_i(\bm{\theta}_2) \forall i \in \{1,...,n\}$ and
$\exists i \in \{1,...n\}, \epsilon_i(\bm{\theta}_1) < \epsilon_i(\bm{\theta}_2)$.
We say that $\bm{\theta}_n$ is Pareto efficient if $\nexists \bm{\theta}_i \in \Theta, \bm{\theta}_i \nprec \bm{\theta}_1$.

The Pareto set $\Theta^{(p)}$ is the set of all Pareto effcient points, that is the set of nondominated points.  While performance requirements have not yet been encoded to determine $\bm{\theta}^*$, this point must fall in the Pareto set, $\bm{\theta}^* \in \Theta$.  If $\epsilon_i$ are competiing, then clearly there are parameterizations which performs well with respect to $\epsilon_i$, but poorly with respect to $\epsilon_j$.

We originally defined $\Theta$ as a compact space of the parameters ${\bm{\theta}}$ defining the feasible $\theta$-space.  In a deterministic approach we would want to identify an algorithm such that we start with feasible set of parameterizations and constrains the sets of parameterizations until it produces a set of parameterizations which produces the Pareto set in $\epsilon$-space, that is a process
\begin{equation}
    \Theta = \Theta_0 \supset \Theta_1 \supset \hdots \supset \Theta_k = \Theta^{(p)}
\end{equation}
which produces due to Eq \ref{eqn:def_Q} and \ref{eqn:def_E}
\begin{equation}
    \mathcal{E} = \mathcal{E}_0 \subset \mathcal{E}_1 \supset \hdots \supset \mathcal{E}_k = \mathcal{E}^{(p)}
\end{equation}
for $k < \infty$ iterations.  Since $\Theta \subset \mathbb{R}^p$ and $\mathcal{E} \subset \mathbb{R}^n$, we provide the following approach which uses Monte Carlo simulation in an approach which is inspired by Bayesian inference, although this approach does not use a Bayesian updating approach.  The goal of this approach is to produce an ensemble of $\bm{\theta}\in \Theta^{(p)}$ and describe this ensemble as a probability distribution which could be used as a starting point in uncertainty quantification propagation.

We propose the following approach:
\begin{subequations}
\begin{gather}
      \Theta_k \rightarrow \hat{Q}_k(\Theta_k) \rightarrow \mathcal{E}_k(\Theta_k) \\
      \mathcal{E}_k(\Theta_k) \rightarrow \mathcal{E}_k^{(p)}(\Theta_k^{(p)}) \\
      \mathcal{E}_k^{(p)}(\Theta_k^{(p)}) \rightarrow \mathcal{E}_k^{(cp)}(\Theta_k^{(cp)}) \\
      \mathcal{E}_k^{(cp)}(\Theta_k^{(cp)}) \rightarrow \Theta_{k+1}
\end{gather}
\end{subequations}
% this paragraph has some notational abuse, but is used for the sake of clarity rather than making the notation mathematical rigorous.
The notation $\rho(\bm{\theta})$ refers to the joint probability density function that $\bm{\theta} \in \Theta^{P}$.
Intuitively, one can think of
$\rho(\bm{\theta})\Delta\bm{\theta}$
as the probability that a random variable drawn from $\rho(\bm{\theta})$ will fall within the infinitesimal compact set $[\bm{\theta},\bm{\theta}+\Delta\bm{\theta}]$

Even if $\Theta$ is defined as compact, $\hat{Q}$ may not be bounded.  By construction $\hat{q}_i > 0 $, however $\hat{q}_i$ may not be bounded from above.  There exists $\bm{\theta} \in \Theta$ which produces pathological members of the Pareto set.  Specifically, there is exists $\bm{\theta} \in \Theta$ such that $\bm{\epsilon}(\theta) \in \mathcal{E}^(p)$, but produces an $\epsilon_i(\bm{\theta}) > \epsilon_{i,max}$ for at least one $i\in\{1,...,n\}$, where $\epsilon_{i,max}$ is an arbitrary performance requirement.

We generalize Eq
To estimate $\Theta^{(p)}$, we simplify the drawing of samples from a uniform distribution defined by hyperrectangles which defines $\Theta$The choice of
\subsubsection{Kernel Density Estimate}

The Kullbach-Leiber divergence\cite{kullback1997} measures the divergence between two probability density functions $f(x)$ and $g(x)$,
\begin{equation}\label{eq:kld}
   D(f \parallel g) = \int f(x) \log \frac{f(x)}
                                          {g(x)} dx
\end{equation}
is commonly used in statistics as a measure of similarity between two density distributions, and has the following properties: (1) self-similarity, $D(f \parallel f) = 0$, (2) self-identification, $D(f \parallel g) = 0$ only if $f=g$, and (3) positivity, $D(f \parallel g) \geq 0$ for all $f$ and $g$.

The integral in Equation \ref{eq:kld} can be calculated from Monte Carlo\cite{hershey2007kld}, by drawing a sample $x_i$, from $f$ such that $\mathbb{E}\left[\log\frac{f(x)}{g(x)}\right] = D(f \parallel g)$.  Using $N$ i.i.d. samples $\left\{x_i\right\}_{i=1}^N$, we have
\begin{equation}
  \label{eq:kdmc}
  D_{MC}(f \parallel g) = \frac{1}{N}\sum_i^N \log \frac{f(x)}{g(x)}
      \rightarrow D(f \parallel g)
\end{equation}
as $n \rightarrow \infty$.  The variance of the estimation error is $\frac{1}{N}\mathrm{Var}_f\left[\log\frac{f}{g}\right]$.  To compute $D_{\mathrm{MC}}(f \parallel g)$, we need to generate samples $\left\{x_i\right\}_{i=1}^N$ from $f$.  Then for $1 \leq i \leq N$, evaluate $f(x_i)$ and $g(x_i)$ to calculate $D_{\mathrm{MC}}$.

\section{Methodology}
To demonstrate the potential of this process to develop a working potential, a Coulumb-Buckingham potential\cite{buckingham1938} is developed for magnesium oxide (MgO).  This pair wise potential for atoms $i$ and $j$
\begin{equation}
    \label{eq:buck_eq}
    V(r_{ij};A,\rho,C)
        = \frac{Z_i Z_j}{4 \pi \varepsilon_0 r_{ij}}
            + A \exp(-\frac{r_{ij}}{\rho})
            - \frac{C}{r_{ij}^6}
\end{equation}
where $r_{ij} = \lVert \bm{r}_i - \bm{r}_j \rVert_2$ is the distance between the atoms $i$ and $j$, and $q_i$ are$q_i$ describe the charges of the atoms, and $A$, $B$, and $C$, are the parameters of the potential.  The first term of the potential is the electrostatic potential energy, the second term is repulsive due to the Pauli exclusion principle, and the third term is an attractive van der Waals energy.

We use the same relevant assumptions used in Lewis and Catlow\cite{lewis1985potential}, the Mg-Mg interactions are assumped to be purely coulombic, the Mg-O is considered to be the Born-Mayer form, $A \exp(-r/\rho)$, where the van der Waals term is ignored.

The charge of the atoms is allowed to deviate from their formal charges, provided that $Z_{Mg} = - Z_{O}$, to preserve charge neutrality.
\subsection{Reference Values}

\subsection{Implementation}
Implemented in Python using LAMMPS as the molecular dynamics engine as the calculator.  Parrellization is done through MPI.
