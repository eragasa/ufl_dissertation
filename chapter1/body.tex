\chapter{INTRODUCTION}\label{intro}

As compututational power has increased so has the size and complexity of simulations.  The use of analytical empirical potentials has been part of computational materials science from the start, and they are instrumental in simulations utilizing lattice dynamics and molecular dynamics.

Instead of conducting electronic structure calculations typical of quantum mechanical simulation methods to get the energies and forces necessary to evolve a system, an analytical potential consists of a formalism which captures the relevant physics of a system with formulas which are a function of relative atomic positions.  The avoidance of expensive electronic structure calculations makes analytical potentials a computational inexpensive surrogate, which enables dynamic simulations of materials systems several orders of magnitude larger than quantum mechanical techniques in both the number of atoms in a simulation and the simulated time length.

One of the limiting factors for molecular dynamics is the availability of interatomic potentials for materials systems of interest.  The development of interatomic potentials is a human work intensive process that is largely dependent upon the skill and experience of a potential developer.  For many computational material scientsts, the ability to conduct molecular dynamics simulations is contingent upon an analytical potential already existing for their system of interest.

This work presents an emergent framework for automating the development of analytical potentials.

\section{Modernizing Analytical Potential Development}

The modernization of analytical potential development needs to achieve the following goals:
(1) clearly define the problem in its most general terms in what maybe, at times, a more rigorous mathematical exposition than that which is normally presented,
(2) identify the problems with existing methodologies by bringing in terminology and notation from different fields to provide a more general framework for the problem of potential development,
(3) provide a baseline implementation of this framework that provides results which are analytical, transparent, and robust, and
(4) provide an automation framework upon which to do the work.

\section{The Difficulty of Potential Development}

%Despite promising work with the development of machine learning potentials, which promises to provide \emph{ab initio} levels of fidelity, these approaches require large amounts of computational resources to develop the requisite fitting datasets.
%Machine learning potential development is a data hungry approach as to ensure that the problem is not underdetermined due to the large number of degrees of freedom associated with the functional form.  Instead, this work focuses on applying machine learning concepts to analytical interatomic potentials.  These models have a functional form described by equations which attempt to capture the relevant physics associated with a material system.

An interatomic potential has a set of free parameters, which can be used to tailor the potential for a specific material system.  To adapt a functional form to a specific material system, potential development undergoes a process of fitting.  Here, parameters are optimized to minimize the difference between the predicted values and the target values of various material properties.

The fundamental feature of fitting is the inability to minimize the errors for each targeted material property of interest simultaneously; improving the predictive performance of a potential with respect to one material property may degrade the predictive performance of one or more other properties.

The typical process for potential development involves cardinal optimization.  That is the developer's preference are encoded at the beginning of the optimization process into a single objective function, known as the cost function.  Typically, the cost function is the weighted square difference between predicted and target material property values, where a vector of weights expresses the preferences of the potential developer.  Optimization of this cost function leads to a unique parameterization.

If the performance is unacceptable, it can be caused by a multitude of issues.  The cost function may have minimized to the closest local minima based upon the choice of the initial condition, the encoded weighting vector might need to be adjusted to give priority to different material properties, or the optimization algorithm ignored desireable parameterizations that exist in a convex region of prediction space.

All these problems are consequences of introducing the artificial heuristic of a cost function.  The cost function is dependent upon an \emph{a priori} expression of performance preferences before knowing what tradeoffs exist.  The cost function is typically minimized with local optimization techniques when a global solution is desirable, leading to the problem with local minima and a solution dependence upon initial conditions.  The construction of the cost function makes the technique unable to resolve possible parameterizations that exist within convex regions.

Despite the promise of molecular dynamics, the lack of availability of interatomic potentials for many systems limits the applicability of this simulation method.  Potential development is a human intensive process due to current appproaches to parameterization.

This work presents an nascent framework for the automated development of potentials based upon sampling from a probability distribution and evolving that distribution so that the final distribution represents the set of parameterizations which can be described in a way as efficient.

Our potential development approach takes a probabilistic approach, treating the vector of parameters as a random variable, where the variation in the values of the parameters represents the epistemic uncertainty associated with the choice of parameter values.  Epistemic uncertainty is systematic and is representative of unknowns which could be known in principle, but currently does not.  Our algorithm procedurally reduces the epistemic uncertainty, leaving a probability distribution where uncertainty is a function

\section{Outline}
%% CHAPTER 2 SUMMARY
Chapter \ref{ch:md} provides an appropriate level of introduction to molecular dynamics, the predominant tool where analytical potentials are used.

Chapter \ref{ch:potential_development} discusses the  conventional approach to potential development.  Typically, a cost function defined as the weighted sum of square differences between the predicted potential values and their respective target values is used as an objective function which is minimized using local minimization techniques.

An alternative representation to the potential development process is multi-objective optimization (MOO) where more than one objective function is to be minimized simultaneously.  In this MOO approach to potential development, the choice of an optimal model choice must be made in the presence of trade-offs between the choice of sacrificing the fidelity in predicting on material property at the expense of an another.

We accept that the development of a potential largely involves a decision of tradeoffs determined by the potential developer, and this expression of preferences is inherently subjective.  Instead, we search for the set of Pareto optimal parameterizations, from which any optimal parameterization must come.  This transforms potential development from an interactive process requiring the intervention of a potential developer to an automatable process, where potential selection is done after candidate potentials have been identified and the performance tradeoffs are known.

The computational difficulties of the conventional approach to potential development is discussed, and compared to a proposed Monte Carlo sampling techniques using a test problem to elucidate the computational costs and numerical efficiency of the diffent approaches.

%% CHAPTER 4 SUMMARY
Chapter \ref{ch:methodology} introduces a probability framework for representing the uncertainty associated with the parameterization.   After introducing an appropriate level of probability theory and notation, we connect the measure theoretic approach to probability to continuous probability distributions, generation of random variables, and non-parametric probability distributions.  In addition, we review the Bayesian framework for parameter estimation, and adapt that framework to solve MOO problems.

Chapter \ref{ch:methodology} also describes an evolutionary framework which implements a methodology to attain the solution to the MOO problem described in Chapter \ref{ch:potential_development}.  Here, we treat potential optimization as a verification, validation, and uncertainty quantification (VVUQ) process with the epistemic uncertainty associated with choosing a parameter expressed as a probability distribution.  To evolve the probability distribution, we describe an iterative Monte Carlo method which adapts Bayesian inference concepts to a multi-objective context to estimate the probability density of the location of Pareto optimal parameterizations.

%% CHAPTER 6 SUMMMARY
Chapter \ref{ch:software} describes the implementation of the evolutionary framework into a software package \verb|pypospack|.  Here we decompose the parameterization process into general base classes.  For example, calculating a material property requires (1) defining a potential, (2) an atomic configuration, (3) a process for calculating the material property, and (4) the individual simulations necessary to calculate these properties.  \verb|pypospack| implements a base class for each of these components.  This provides a consistent, reuseable, and extendable modeling framework for potential developers to define the performance variables for the potential parameter optimization process.

\verb|pypospack| is integrated to work with popular external simulation codes, which alleviates the problems with implementing new software routines, such as structural relaxation and the implementation of an existing potential formalism.  A variety of parameter optimization algorithms are already implemented.

\verb|pypospack| is conceived largely as software library to model structure property relationships from constituent simulations, and a framework to automate the workflows.  This software is licensed under a permissive open-source license to encourage potential developers to extend and integrate this library into their own potential development schemes.

Chapters \ref{ch:ionic_MgO} goes through the development of a Buckingham style potential on a prototypical oxide, magnesium oxide.

Chapter \ref{ch:pareto_si} goes through the Pareto optimization process for Stillinger-Weber potential for silicon.  Instead of the selection of potentials, this chapter discusses clustering methods to reduce the number of potentials analyzed.

Chapter \ref{ch:summary} summarizes the work, and speculates on the possible direction new research.
